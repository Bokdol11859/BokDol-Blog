---
title: 밑바닥부터 시작하는 딥러닝 | 신경망
date: '2021-12-6'
tags: ['딥러닝', '인공지능']
draft: false
summary: 딥러닝 신경망 이론
---

# 신경망 Neural Network

- 퍼셉트론의 문제점
  - 1층 퍼셉트론으로는 선형분리 외의 문제를 해결할 수 없음 (XOR)
  - MLP: 층을 늘리면 해결 가능

## 다층 신경망![](https://images.velog.io/images/bokdol11859/post/07eae7b3-c72a-4793-a685-066dae6ec9ce/Screen%20Shot%202021-12-06%20at%205.28.16%20PM.png)

층이 총 세개로 구성이 되어있지만, 가중치를 갖는 층은 입력층과 은닉층 두개이기 때문에 위 그림은 2층 신경망이다.

## 활성화 함수 h(x)

입력 신호의 총합을 출력 신호로 변환하는 함수
![](https://images.velog.io/images/bokdol11859/post/e82134c1-12fd-477b-a872-0ab7320444c5/Screen%20Shot%202021-12-06%20at%205.37.26%20PM.png)

활성화 함수의 처리 과정을 기존 퍼셉트론에 추가한다면
![](https://images.velog.io/images/bokdol11859/post/ccf33e03-7ffd-48df-a9b7-205bdb69b46e/Screen%20Shot%202021-12-06%20at%205.38.54%20PM.png)

### 활성화 함수의 종류

1. **계단 함수 (Step Function)** - 0을 기준으로 출력값이 갑자기 변화
   ![](https://images.velog.io/images/bokdol11859/post/e616296c-53f1-437a-8506-51b46053b7ad/Screen%20Shot%202021-12-06%20at%205.40.15%20PM.png)
2. **시그모이드 함수 (Sigmoid Function)** - 0과 1 사이의 연속적인 출력 - 미분이 가능하다
   ![](https://images.velog.io/images/bokdol11859/post/ebb89cf5-cd47-4b3c-a50d-7db94a5c14ac/Screen%20Shot%202021-12-06%20at%205.41.40%20PM.png)
   ![](https://images.velog.io/images/bokdol11859/post/57ce69f9-5569-4e6c-b46f-024fdb4c6dff/Screen%20Shot%202021-12-06%20at%205.42.10%20PM.png)
3. **ReLU (Rectified Linear Unit) 함수** - 입력이 0 이하이면 0을 출력 - 입력이 0 이상이면 입력을 그대로 출력
   ![](https://images.velog.io/images/bokdol11859/post/bbf9b7d3-089a-4423-bddd-1f993361fb39/Screen%20Shot%202021-12-06%20at%205.54.44%20PM.png)
4. **항등 함수 (Identity Function)** - 출력층에서 사용하는 활성화 함수 - 입력을 그대로 출력
   ![](https://images.velog.io/images/bokdol11859/post/3d0ae4ca-2494-4563-a90e-56ad856ce94b/Screen%20Shot%202021-12-06%20at%206.12.13%20PM.png)

5. **소프트맥스 함수 (Softmax Function)**

   - 클래스 분류를 위해 마지막 출력값을 정규화 하는 함수
   - 모든 결과 수치의 합을 1.0으로 만들어 주기에 각 클래스에 대한 확률로써 수치화하기에 좋음
   - ![](https://images.velog.io/images/bokdol11859/post/5666daab-5d8c-4e6d-ad69-0214a14f2081/Screen%20Shot%202021-12-06%20at%206.14.49%20PM.png)
   - 분자는 입력 신호의 지수 함수
   - 분모는 모든 입력 신호의 지수 함수의 합

   - ![](https://images.velog.io/images/bokdol11859/post/94793f73-e332-47c3-8f17-da3b3023ec97/Screen%20Shot%202021-12-06%20at%206.16.49%20PM.png)
   - 소프트맥스 함수를 적용해도 각 원소의 대소 관계는 변하지 않음

### 계단 함수와 시그모이드 함수의 차이

차이점 1

- 시그모이드는 부드러운 곡선이며 입력에 따라 출력이 연속적으로 변화
- 계단 함수는 0을 경계로 출력이 갑자기 변화

차이점 2

- 시그모이드는 0과 1 사이의 실수를 반환
- 계단 함수는 0 아니면 1 둥 중 하나의 값 반환

공통점

- 입력이 작을 때 출력은 0 입력이 커지면 출력이 1이 되는 구조
- 입력이 아무리 작거나 커도 출력은 0에서 1 사이의 값
- 비선형 함수
  - 직선 하나로는 그릴 수 없는 함수

## 퍼셉트론과 신경망의 차이

- 뉴런이 여러 층으로 이어지는 구조나 신호 전달 방법은 같다
- 활성화 함수가 계단 함수가 아닌 다른 함수로 변경
  - 신경망에서는 계단 함수가 아닌 시그모이드 함수를 사용한다

## 지도학습 Supervised Learning

- 분류 Classification

  - 미리 정의된 클래스 중 하나를 예측하는 것
    - 스팸메일 / 정상메일 분류
    - 손글씨 분류
      - (0, 1, ..., 9)
  - 출력층에서 **소프트 맥스** 함수 사용

- 회귀 Regression
  - 연속적인 수를 예측하는 것
    - 기상데이터로 내일 기온 예측
    - 공부시간으로 성적 예측
      - (10점, 11.5점, 27점, 등등)
  - 출력층에서 **항등 함수** 사용

## 출력층의 뉴런 수 정하기

- 출력층의 뉴런 수는 풀려는 문제에 맞게 적절히 정해야 함
  - 분류에서는 분류하고 싶은 클래스 수로 설정하는 것이 일반적
    - 숫자 손글씨 이미지를 0~9로 분류하는 문제라면 출력층의 뉴런은 10개

![](https://images.velog.io/images/bokdol11859/post/d081c0b1-1359-4f8f-8222-b627dc6cc689/Screen%20Shot%202021-12-06%20at%206.25.04%20PM.png)
